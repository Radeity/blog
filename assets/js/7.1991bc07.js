(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{511:function(s,a,t){s.exports=t.p+"assets/img/image-20210820225419279.75c4d8f2.png"},512:function(s,a,t){s.exports=t.p+"assets/img/IMG_7530.f961a219.png"},513:function(s,a,t){s.exports=t.p+"assets/img/image-20210820194850968.e71e53ea.png"},514:function(s,a,t){s.exports=t.p+"assets/img/image-20210820201856126.4e35b77f.png"},515:function(s,a,t){s.exports=t.p+"assets/img/image-20210820202122276.14aa0d08.png"},516:function(s,a,t){s.exports=t.p+"assets/img/image-20210820210834416.b8f95a9d.png"},538:function(s,a,t){"use strict";t.r(a);var n=t(6),e=Object(n.a)({},(function(){var s=this,a=s.$createElement,n=s._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("p",[n("img",{attrs:{src:t(511),alt:"image-20210820225419279"}})]),s._v(" "),n("p",[s._v("计算机中所有程序都要寄托一个环境运行，环境可以理解为一个程序运行所需要的条件的集合；如果只是为了写一个Java程序，它是单进程的，那么我们配置jdk、jre就可以了；如果写一个网站，有前后端、数据库服务、缓存服务等等，它们都要跑在不同的端口乃至不同的服务器上，配置环境让他们可以协同运作就会变得稍微复杂一些了；本篇文章将会介绍一个同样复杂的环境配置 —— Spark + Hadoop。")]),s._v(" "),n("p",[s._v("由于 Spark和Hadoop通常都运行于"),n("strong",[s._v("分布式环境")]),s._v("，有主从节点，因此一般在Linux服务器集群进行分布式生产环境部署，但很多人在学习时可能是没有多台服务器可以练手的，这时通常会选择用虚拟化的技术实现分布式，这里的选择就包括了"),n("strong",[s._v("虚拟机")]),s._v("和"),n("strong",[s._v("Docker")]),s._v("。")]),s._v(" "),n("h3",{attrs:{id:"docker-vs-虚拟机"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#docker-vs-虚拟机"}},[s._v("#")]),s._v(" Docker vs 虚拟机")]),s._v(" "),n("p",[s._v("虚拟机就是用系统镜像去创建，"),n("strong",[s._v("虚拟出硬件资源")]),s._v("直接跑一个完整的操作系统，虚拟机运行时你的电脑硬件资源被拆分后跑两个操作系统，配置分布式多节点就要跑多个完整的操作系统，想必性能受限；")]),s._v(" "),n("p",[s._v("Docker是一个沙箱环境， 它在宿主机内核的基础上"),n("strong",[s._v("虚拟出了一个操作系统")]),s._v("，更适合对不同应用的"),n("strong",[s._v("隔离")]),s._v("，隔离程度没有虚拟机高，不用内核，没那么占据存储空间。")]),s._v(" "),n("p",[n("img",{attrs:{src:t(512),alt:"IMG_7530"}})]),s._v(" "),n("p",[s._v("再看看我们的需求，只需要虚拟出多个节点进行Hadoop和Spark的实验，不需要考虑真实的集群生产环境，没必要虚拟完整的操作系统，因此选择用Docker来部署本地的分布式环境。当然，更直观的一个原因是，Docker在内存和存储的消耗比虚拟机小得多，本地实验更友好。")]),s._v(" "),n("h3",{attrs:{id:"docker-镜像"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#docker-镜像"}},[s._v("#")]),s._v(" Docker 镜像")]),s._v(" "),n("p",[s._v("首先拉一个docker的centos7镜像（确保已经装了docker），发现只有200M，和虚拟机上运行的5G镜像差了20多倍，原因前面提及过，操作系统是内核加文件系统，而Docker容器运行使用的是宿主机的内核，因此Docker镜像仅包含了挂载在宿主机内核上的"),n("strong",[s._v("根文件系统")]),s._v("，叫做"),n("strong",[s._v("Union FS")]),s._v("，它是适配了Docker分层结构的一个文件系统。Linux中的根文件系统是文件系统特殊的一种，通常在操作系统启动阶段加载到内存中，挂载了根文件系统才能逻辑性的去访问磁盘，才能去使用基本的shell命令，才能去加载一些系统的配置文件。文件系统就是为了硬件能与用户交互产生的，因此我们在开启一个有根文件系统的容器时，也觉得像在使用一个完整的操作系统。")]),s._v(" "),n("p",[s._v("镜像是只读的，容器相当于“实例化”镜像，它记录了对镜像的修改，可以在当前镜像的基础上叠加修改内容构建出一个新的镜像，由于是分层模式，一个镜像应该尽量简洁仅包含当前环境，删除掉一些无关数据；构建一个新镜像常用的两种方法是commit和Dockerfile，commit是基于当前容器构建镜像，构建出来的镜像像一个黑箱，Dockerfile是从头开始根据一行行指令去构建新镜像，逻辑更加清晰。")]),s._v(" "),n("h3",{attrs:{id:"启动容器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#启动容器"}},[s._v("#")]),s._v(" 启动容器")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ docker  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 确认Docker可以正常运行")]),s._v("\n$ docker pull centos:centos7  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 拉镜像")]),s._v("\n$ docker image "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("ls")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看镜像")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br")])]),n("p",[s._v("启动Docker就是启动了一个父进程Docker Daemon，Docker内启动每个容器都是启动Docker Daemon的一个子进程，子进程下有它自己的命名空间。")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ docker run -it --name linux1 centos /bin/bash\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("p",[s._v("启动容器后可以在宿主机命令行执行 docker ps 查看容器运行状态，也可以执行 docker inspect 容器ID 查看容器运行的各种相关数据。")]),s._v(" "),n("p",[s._v("接下来都在容器的bash中执行命令。")]),s._v(" "),n("hr"),s._v(" "),n("p",[s._v("首先我们需要安装Hadoop、Spark及相关应用程序到容器中，可以wget下tar包，也可以使用 docker cp 命令将本地tar包拷贝到指定的容器目录下，解压tar包；通常用户程序我们拷贝到 /opt 中，另外还要注意彼此的版本依赖。当然，也可以在我们本地解压好直接cp到容器中。")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" /opt\n$ yum "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v("\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" https://downloads.lightbend.com/scala/2.12.14/scala-2.12.14.tgz\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" Hadoop下载地址\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" Spark下载地址\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" https://repo.huaweicloud.com/java/jdk/8u201-b09/jdk-8u201-linux-x64.tar.gz\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("ls")]),s._v("\nhadoop-3.3.1.tar.gz  jdk1.8.0_201.tar.gz\tscala-2.12.14.tgz\tspark-3.1.2-bin-hadoop3.2.tgz\n\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zxvf hadoop-3.3.1.tar.gz\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zxvf scala-2.12.14.tgz\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zxvf spark-3.1.2-bin-hadoop3.2.tgz\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zxvf\n\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("ls")]),s._v("\nhadoop-3.3.1  jdk1.8.0_201  scala-2.12.14  spark-3.1.2-bin-hadoop3.2\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br")])]),n("h3",{attrs:{id:"配置java-scala环境变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#配置java-scala环境变量"}},[s._v("#")]),s._v(" 配置Java, Scala环境变量")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vi")]),s._v(" /etc/profile\n\n// Java\n"),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JAVA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/jdk1.8.0_201/ \n"),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JAVA_BIN")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JAVA_HOME}")]),s._v("/bin \n"),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JRE_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JAVA_HOME}")]),s._v("/jre "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("CLASSPATH")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JRE_HOME}")]),s._v("/lib:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JAVA_HOME}")]),s._v("/lib:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JRE_HOME}")]),s._v("/lib/charsets.jar \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v("  JAVA_HOME  JAVA_BIN JRE_HOME  "),n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")]),s._v("  CLASSPATH\n// Scala \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SCALA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/scala-2.12.12 \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$SCALA_HOME")]),s._v("/bin\n\n$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("source")]),s._v(" /etc/profile\n\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vi")]),s._v(" ~/.bashrc\n\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JAVA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/jdk1.8.0_201 \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$JAVA_HOME")]),s._v("/bin:"),n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),s._v(" \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("CLASSPATH")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(".:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$JAVA_HOME")]),s._v("/lib/dt.jar:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$JAVA_HOME")]),s._v("/lib/tools.jar\n\n$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("source")]),s._v(" ~/.bashrc\n$ Java -version\n$ scala -version\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br")])]),n("h3",{attrs:{id:"配置hadoop"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#配置hadoop"}},[s._v("#")]),s._v(" 配置Hadoop")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" /opt/hadoop-3.3.1\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vi")]),s._v(" etc/hadoop/hadoop-env.sh\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("p",[s._v("末尾添加jdk目录")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JAVA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/jdk1.8.0_201\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("p",[s._v("配置Hadoop环境变量")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vi")]),s._v(" ~/.bashrc\n\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HADOOP_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/opt/hadoop-3.3.1\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${JAVA_HOME}")]),s._v("/bin:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${HADOOP_HOME}")]),s._v("/bin:"),n("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${HADOOP_HOME}")]),s._v("/sbin\n\n$ hadoop version "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 验证环境变量生效")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br")])]),n("h3",{attrs:{id:"安装ssh"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#安装ssh"}},[s._v("#")]),s._v(" 安装SSH")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ yum "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" openssh-clients\n$ yum "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" openssh-server\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("h3",{attrs:{id:"配置免密登陆"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#配置免密登陆"}},[s._v("#")]),s._v(" 配置免密登陆")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" ~/.ssh\n$ ssh-keygen -t rsa\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("cat")]),s._v(" ~/.ssh/id_rsa.pub "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" ~/.ssh/authorized_keys\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br")])]),n("p",[s._v("笔者在测试时ssh localhost报错：ssh: connect to host localhost port 22: Cannot assign requested address；判断ssh服务没开启，但用systemctl开启服务时报错：")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("System has not been booted with systemd as init system "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("PID "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(". Can't operate.\nFailed to connect to bus: Host is down\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("p",[s._v("只能手动去开启，分两步：")]),s._v(" "),n("p",[s._v("（1）生成 host_key")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key\n$ ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key\n$ ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v("\n$ ssh-keygen -t dsa -f /etc/ssh/ssh_host_ed25519_key\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("p",[s._v("（2）启动SSH服务")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ /usr/sbin/sshd -f /etc/ssh/sshd_config\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("h3",{attrs:{id:"将当前容器打包成镜像"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#将当前容器打包成镜像"}},[s._v("#")]),s._v(" 将当前容器打包成镜像")]),s._v(" "),n("p",[s._v('docker commit -m "centos7 with hadoop and ssh" linux1 centos7-hadoop-ssh')]),s._v(" "),n("h3",{attrs:{id:"开启三个容器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#开启三个容器"}},[s._v("#")]),s._v(" 开启三个容器")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ docker run --name hadoop0 --hostname hadoop0 --privileged"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true -P -p  "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("50070")]),s._v(":50070 -p "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8088")]),s._v(":8088 -p "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("9870")]),s._v(":9870 -p  "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("9864")]),s._v(":9864 -p "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8080")]),s._v(":8080 centos7-hadoop-ssh  \n\n$ docker run --name hadoop1 --hostname hadoop1 --privileged"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true  centos7-hadoop-ssh  \n\n$ docker run --name hadoop2 --hostname hadoop2 --privileged"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true centos7-hadoop-ssh  \n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br")])]),n("h3",{attrs:{id:"host配置主机名和ip地址的映射"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#host配置主机名和ip地址的映射"}},[s._v("#")]),s._v(" host配置主机名和IP地址的映射")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vi")]),s._v(" /etc/hosts\n\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("172.17")]),s._v(".0.4      hadoop2\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("172.17")]),s._v(".0.2      hadoop1\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("172.17")]),s._v(".0.3      hadoop0\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br")])]),n("p",[s._v("测试过可以互相ping通，且可以互相ssh连接，不难理解为什么，在最开始的容器中，我们已经生成了SSH密钥对，并将公钥放入了authorized_keys中，SSH是通过非对称加密进行的认证，带着公钥进行SSH连接就可以通过认证实现免密登陆，由于我们是先通过容器创建镜像，用同一个镜像又开了三个容器，这样每个容器都有相同的公私钥，自然就可以通过其它容器的认证了。")]),s._v(" "),n("h3",{attrs:{id:"三个容器上配置hadoop"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#三个容器上配置hadoop"}},[s._v("#")]),s._v(" 三个容器上配置Hadoop")]),s._v(" "),n("p",[s._v("这里配置内容和Hadoop_env所讲类似，可以参考那篇文章。")]),s._v(" "),n("p",[s._v("另外还需要修改$HADOOP_HOME/etc/hadoop/hadoop-env.sh，添加：")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HDFS_NAMENODE_USER")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HDFS_DATANODE_USER")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HDFS_SECONDARYNAMENODE_USER")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("YARN_RESOURCEMANAGER_USER")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("YARN_NODEMANAGER_USER")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br")])]),n("p",[s._v("在$HADOOP_HOME/etc/hadoop/目录下新建slaves文件，配置DataNode节点，不做此配置DataNode节点无法启动。")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("vim")]),s._v(" etc/hadoop/slaves\n\nhadoop1\nhadoop2\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("p",[s._v("配置完使用scp将配置分发到Hadoop1和hadoop2上")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("scp")]),s._v("  -rq /opt/hadoop-3.3.1   hadoop1:/opt\n$ "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("scp")]),s._v("  -rq /opt/hadoop-3.3.1   hadoop2:/opt\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("p",[s._v("确定之前配置文件中的tmp和namenode、datanode路径都存在，没有则创建；确定可以使用which，没有则yum install -y which。")]),s._v(" "),n("p",[s._v("首次启动集群需要在hadoop0格式化namenode")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ bin/hdfs namenode -format\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("p",[s._v("hadoop0为namenode节点，hadoop1~3均为datanode节点，三个容器中都启动hdfs。")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ sbin/start-dfs.sh\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("p",[s._v("每个容器内可以使用 jps 确定一下对应的进程是否启动成功。")]),s._v(" "),n("p",[s._v("因为在启动docker的时候做了端口映射，直接localhost:9870就可以访问namenode的web页面：")]),s._v(" "),n("p",[n("img",{attrs:{src:t(513),alt:"image-20210820194850968"}})]),s._v(" "),n("h3",{attrs:{id:"启动spark"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#启动spark"}},[s._v("#")]),s._v(" 启动Spark")]),s._v(" "),n("p",[s._v("在master节点的对应容器内进入Spark目录，执行：")]),s._v(" "),n("div",{staticClass:"language-Bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v("$ ./sbin/start-master.sh\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br")])]),n("p",[s._v("在映射的8080端口查看master节点启动成功：")]),s._v(" "),n("p",[n("img",{attrs:{src:t(514),alt:"image-20210820201856126"}})]),s._v(" "),n("p",[s._v("记录下上面的URL，进入Worker节点对应的容器Spark目录下，")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ./sbin/start-worker.sh <url>")]),s._v("\n$ ./sbin/start-worker.sh spark://hadoop0:7077\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("p",[s._v("启动成功后在之前Master节点的web页面下可以看到")]),s._v(" "),n("p",[n("img",{attrs:{src:t(515),alt:"image-20210820202122276"}})]),s._v(" "),n("h3",{attrs:{id:"测试spark"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#测试spark"}},[s._v("#")]),s._v(" 测试Spark")]),s._v(" "),n("p",[s._v("运行官方样例 —— 计算Pi")]),s._v(" "),n("div",{staticClass:"language-bash line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[s._v(".bin/spark-submit --class org.apache.spark.examples.SparkPi "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--master spark://hadoop0:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\nexamples/jars/spark-examples_2.12-3.1.2.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("p",[s._v("查看执行情况：")]),s._v(" "),n("p",[n("img",{attrs:{src:t(516),alt:"image-20210820210834416"}})]),s._v(" "),n("p",[s._v("综上，我们的Docker模拟完全分布式Hadoop+Spark集群就已经搭建完毕，并且通过了测试。")]),s._v(" "),n("p",[s._v("之后会一点点进行 Spark 学习的经验分享！")])])}),[],!1,null,null,null);a.default=e.exports}}]);